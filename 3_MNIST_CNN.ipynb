{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "# 3.Computer Vision : CNN for digit recognition "
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import torch \nimport torch.cuda as cuda \nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nfrom torch.autograd import Variable \n\nfrom torchvision import datasets\nfrom torchvision import transforms \n\nimport torch.nn.functional as F",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ea07bba51b465caea4185ec6aa6dca0fc07a326"
      },
      "cell_type": "code",
      "source": "## Create data loader\nmean_gray = 0.1307\nstddev_gray = 0.3081 \ntransform = transforms.Compose([transforms.ToTensor(),\n                              transforms.Normalize((mean_gray,),(stddev_gray,))])\n\nmnist_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\nmnist_valid = datasets.MNIST('./data', train=False, download=True, transform=transform)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92a70727e229e3bb0fc7cd1cfe225b8eaf0eec41"
      },
      "cell_type": "code",
      "source": "img = mnist_train[12][0].numpy() * stddev_gray + mean_gray\n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3c0ad2a06d1ae3ac8b46ff214acc42aabe8cb89"
      },
      "cell_type": "code",
      "source": "plt.imshow(img.reshape(28, 28), cmap='gray')\n",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7f59d2f16e10>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f92c4fc4ff68b11e04f98e377b7cceb7ae821121"
      },
      "cell_type": "code",
      "source": "label = mnist_train[12][1]\nlabel",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "tensor(3)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d83bb2107c05f0e87ea71eed780a91236ca7bfd"
      },
      "cell_type": "code",
      "source": "batch_size= 1024",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4871a7e9870d32abc4cb913e6cbccb803168c65e"
      },
      "cell_type": "code",
      "source": "mnist_train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=1)\nmnist_valid_loader = torch.utils.data.DataLoader(mnist_valid, batch_size=batch_size, shuffle=True, num_workers=1)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85035a8bf62bf026eaac7700abde3af0a6bbc0fa"
      },
      "cell_type": "code",
      "source": "class MNISTNet(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n               \n        # NOTE: All Conv2d layers have a default padding of 0 and stride of 1,\n        # which is what we are using.\n        \n        # Convolution Layer 1                             # 28 x 28 x 1  (input)\n        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)      # 24 x 24 x 20  (after 1st convolution)\n        self.relu1 = nn.ReLU()                            # Same as above\n        \n        # Convolution Layer 2\n        self.conv2 = nn.Conv2d(20, 30, kernel_size=5)     # 20 x 20 x 30  (after 2nd convolution)\n        self.conv2_drop = nn.Dropout2d(p=0.5)             # Same as above\n        self.maxpool2 = nn.MaxPool2d(2)                   # 10 x 10 x 30  (after pooling)\n        self.relu2 = nn.ReLU()                            # Same as above \n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(3000, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        \n        # Convolution Layer 1                    \n        x = self.conv1(x)                        \n        x = self.relu1(x)                        \n        \n        # Convolution Layer 2\n        x = self.conv2(x)               \n        x = self.conv2_drop(x)\n        x = self.maxpool2(x)\n        x = self.relu2(x)\n        \n        # Switch from activation maps to vectors\n        x = x.view(-1, 3000)\n        \n        # Fully connected layer 1\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = F.dropout(x, training=True)\n        \n        # Fully connected layer 2\n        x = self.fc2(x)\n        \n        return x",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5d77175429c32fa59a28a6dfb221ac0cd60482c"
      },
      "cell_type": "markdown",
      "source": "# Create the Object"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f97dcae1967f2cdea8b978d7561438cb216bb178"
      },
      "cell_type": "code",
      "source": "# Model\nnet = MNISTNet()\n\nif cuda.is_available():\n    net = net.cuda()\n    \n\n# Our loss function\ncriterion = nn.CrossEntropyLoss()\n\n#Optimizer\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(net.parameters(),lr = learning_rate, momentum = 0.9)\n\n\n    \n    \n    \n    \n",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f5da1454a6ef6e174794e0184b9aadcdbcc22c8"
      },
      "cell_type": "markdown",
      "source": "# Training Loop"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fff13865dbc964d676b1a46a9a28985477e4c234"
      },
      "cell_type": "code",
      "source": "num_epochs = 100\n\ntrain_loss = []\nvalid_loss = []\ntrain_accuracy = []\nvalid_accuracy = []\n\nfor epoch in range(num_epochs):\n    \n    ############################\n    # Train\n    ############################\n    \n    iter_loss = 0.0\n    correct = 0\n    iterations = 0\n    \n    net.train()                   # Put the network into training mode\n    \n    for i, (items, classes) in enumerate(mnist_train_loader):\n        \n        # Convert torch tensor to Variable\n        items = Variable(items)\n        classes = Variable(classes)\n        \n        # If we have GPU, shift the data to GPU\n        if cuda.is_available():\n            items = items.cuda()\n            classes = classes.cuda()\n        \n        optimizer.zero_grad()     # Clear off the gradients from any past operation\n        outputs = net(items)      # Do the forward pass\n        loss = criterion(outputs, classes) # Calculate the loss\n        iter_loss += loss.item() # Accumulate the loss\n        loss.backward()           # Calculate the gradients with help of back propagation\n        optimizer.step()          # Ask the optimizer to adjust the parameters based on the gradients\n        \n        # Record the correct predictions for training data \n        _, predicted = torch.max(outputs.data, 1)\n        correct += (predicted == classes.data).sum()\n        iterations += 1\n    \n    # Record the training loss\n    train_loss.append(iter_loss/iterations)\n    # Record the training accuracy\n    train_accuracy.append((100 * correct / len(mnist_train_loader.dataset)))\n    \n    \n    ############################\n    # Validate - How did we do on the unseen dataset?\n    ############################\n    \n    loss = 0.0\n    correct = 0\n    iterations = 0\n\n    net.eval()                    # Put the network into evaluate mode\n    \n    for i, (items, classes) in enumerate(mnist_valid_loader):\n        \n        # Convert torch tensor to Variable\n        items = Variable(items)\n        classes = Variable(classes)\n        \n        # If we have GPU, shift the data to GPU\n        if cuda.is_available():\n            items = items.cuda()\n            classes = classes.cuda()\n        \n        outputs = net(items)      # Do the forward pass\n        loss += criterion(outputs, classes).item() # Calculate the loss\n        \n        # Record the correct predictions for training data\n        _, predicted = torch.max(outputs.data, 1)\n        correct += (predicted == classes.data).sum()\n        \n        iterations += 1\n\n    # Record the validation loss\n    valid_loss.append(loss/iterations)\n    # Record the validation accuracy\n    valid_accuracy.append(correct / len(mnist_valid_loader.dataset) * 100.0)\n\n    \n    print ('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n           %(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], \n             valid_loss[-1], valid_accuracy[-1]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5cc1262114239248355a7019ff073763695eacb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}